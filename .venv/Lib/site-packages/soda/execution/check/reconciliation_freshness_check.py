from __future__ import annotations

from datetime import date, datetime, timedelta

from soda.common.exceptions import CheckConfigError
from soda.execution.check.freshness_check import MAX_COLUMN_TIMESTAMP, FreshnessCheck
from soda.execution.check_outcome import CheckOutcome
from soda.execution.metric.metric import Metric
from soda.execution.metric.numeric_query_metric import NumericQueryMetric


class ReconciliationFreshnessCheck(FreshnessCheck):
    def __init__(
        self,
        check_cfg: FreshnessCheckCfg,
        data_source_scan: DataSourceScan,
        partition: Partition,
        column: Column,
    ):
        from soda.execution.table import Table

        super().__init__(
            check_cfg=check_cfg,
            data_source_scan=data_source_scan,
            partition=partition,
            column=column,
        )
        self.freshness_values: dict | None = None

        scan = data_source_scan.scan

        source_config = check_cfg.reconciliation_configurations["source"]
        target_config = check_cfg.reconciliation_configurations["target"]

        source_data_source_scan = scan._get_or_create_data_source_scan(source_config["datasource"])
        source_table: Table = source_data_source_scan.get_or_create_table(source_config["dataset"])
        source_partition = source_table.get_or_create_partition(None)

        target_data_source_scan = scan._get_or_create_data_source_scan(target_config["datasource"])
        target_table: Table = target_data_source_scan.get_or_create_table(target_config["dataset"])
        target_partition = target_table.get_or_create_partition(None)

        self.metrics[f"source_{MAX_COLUMN_TIMESTAMP}"] = data_source_scan.resolve_metric(
            NumericQueryMetric(
                data_source_scan=source_data_source_scan,
                partition=source_partition,
                column=self.column,
                metric_name="max",
                metric_args=None,
                filter=None,
                aggregation=None,
                check_missing_and_valid_cfg=None,
                column_configurations_cfg=None,
                check=self,
            )
        )
        self.metrics[f"target_{MAX_COLUMN_TIMESTAMP}"] = data_source_scan.resolve_metric(
            NumericQueryMetric(
                data_source_scan=target_data_source_scan,
                partition=target_partition,
                column=self.column,
                metric_name="max",
                metric_args=None,
                filter=None,
                aggregation=None,
                check_missing_and_valid_cfg=None,
                column_configurations_cfg=None,
                check=self,
            )
        )

    def evaluate(self, metrics: dict[str, Metric], historic_values: dict[str, object]):
        from soda.sodacl.freshness_check_cfg import FreshnessCheckCfg

        check_cfg: FreshnessCheckCfg = self.check_cfg

        try:
            is_percentage = self.check_threshold_is_percentage(
                self.check_cfg.warn_threshold_cfg, self.check_cfg.fail_threshold_cfg
            )
        except CheckConfigError as e:
            self.logs.warning(e, location=self.check_cfg.location)
            return

        now_variable_name = check_cfg.variable_name
        now_variable_value = self._get_now_variable(now_variable_name)
        if not now_variable_value:
            self.outcome = CheckOutcome.FAIL
            return

        now_variable_timestamp = self._parse_now_variable(now_variable_name, now_variable_value)
        is_now_variable_timestamp_valid = self._is_now_variable_valid(now_variable_value, now_variable_timestamp)

        # Source max time value handling
        source_max_column_timestamp: datetime | None = metrics.get(f"source_{MAX_COLUMN_TIMESTAMP}").value

        if (
            type(source_max_column_timestamp) == date
        ):  # using type instead of isinstance because datetime is subclass of date.
            # Convert data to datetime if its date, use max time (1ms before midnight)
            min_time = datetime.max.time()
            source_max_column_timestamp = datetime.combine(source_max_column_timestamp, min_time)

        is_source_max_column_timestamp_valid = isinstance(source_max_column_timestamp, datetime)
        if not is_source_max_column_timestamp_valid and source_max_column_timestamp is not None:
            self.logs.error(
                f"Could not evaluate freshness: max({self.check_cfg.column_name}) "
                f"is not a datetime: {type(source_max_column_timestamp).__name__}",
                location=self.check_cfg.location,
            )

        # Target max time value handling
        target_max_column_timestamp: datetime | None = metrics.get(f"target_{MAX_COLUMN_TIMESTAMP}").value

        if (
            type(target_max_column_timestamp) == date
        ):  # using type instead of isinstance because datetime is subclass of date.
            # Convert data to datetime if its date, use max time (1ms before midnight)
            min_time = datetime.max.time()
            target_max_column_timestamp = datetime.combine(target_max_column_timestamp, min_time)

        is_target_max_column_timestamp_valid = isinstance(target_max_column_timestamp, datetime)
        if not is_target_max_column_timestamp_valid and target_max_column_timestamp is not None:
            self.logs.error(
                f"Could not evaluate freshness: max({self.check_cfg.column_name}) "
                f"is not a datetime: {type(target_max_column_timestamp).__name__}",
                location=self.check_cfg.location,
            )

        freshness_diff = None
        freshness_diff_percentage = None
        source_freshness = None
        target_freshness = None

        source_max_column_timestamp_utc = (
            self._datetime_to_utc(source_max_column_timestamp) if source_max_column_timestamp else None
        )
        target_max_column_timestamp_utc = (
            self._datetime_to_utc(target_max_column_timestamp) if target_max_column_timestamp else None
        )
        now_timestamp_utc = self._datetime_to_utc(now_variable_timestamp) if now_variable_timestamp else None

        if (
            is_source_max_column_timestamp_valid
            and is_target_max_column_timestamp_valid
            and is_now_variable_timestamp_valid
        ):
            source_freshness = now_timestamp_utc - source_max_column_timestamp_utc
            target_freshness = now_timestamp_utc - target_max_column_timestamp_utc

            # Freshness diff is non intuitively target - source as freshness goes into past.
            freshness_diff = abs(target_freshness - source_freshness)
            freshness_diff_percentage = abs(round((freshness_diff / target_freshness) * 100, 2))

            if is_percentage:
                freshness_value = freshness_diff_percentage
            elif not is_percentage:
                freshness_value = freshness_diff

            if check_cfg.fail_freshness_threshold is not None and freshness_value > check_cfg.fail_freshness_threshold:
                self.outcome = CheckOutcome.FAIL
            elif (
                check_cfg.warn_freshness_threshold is not None and freshness_value > check_cfg.warn_freshness_threshold
            ):
                self.outcome = CheckOutcome.WARN
            else:
                self.outcome = CheckOutcome.PASS
        elif source_max_column_timestamp is None or target_max_column_timestamp is None:
            self.outcome = CheckOutcome.FAIL

        self.freshness_values = {
            "source_max_column_timestamp": str(source_max_column_timestamp) if source_max_column_timestamp else None,
            "source_max_column_timestamp_utc": str(source_max_column_timestamp_utc)
            if source_max_column_timestamp_utc
            else None,
            "target_max_column_timestamp": str(target_max_column_timestamp) if target_max_column_timestamp else None,
            "target_max_column_timestamp_utc": str(target_max_column_timestamp_utc)
            if target_max_column_timestamp_utc
            else None,
            "now_variable_name": now_variable_name,
            "now_timestamp": now_variable_value,
            "now_timestamp_utc": str(now_timestamp_utc) if now_timestamp_utc else None,
            "source_freshness": source_freshness,
            "target_freshness": target_freshness,
            "freshness_diff": freshness_diff,
            "freshness_diff_percentage": f"{freshness_diff_percentage}%",
            "check_value": freshness_value,
        }

    def get_cloud_diagnostics_dict(self):
        cloud_diagnostics = {}

        freshness_diff = 0
        if self.freshness_values["freshness_diff"] and isinstance(self.freshness_values["freshness_diff"], timedelta):
            freshness_diff = round(self.freshness_values["freshness_diff"].total_seconds() * 1000)

        cloud_diagnostics["value"] = freshness_diff  # milliseconds difference
        cloud_diagnostics["measure"] = "time"
        cloud_diagnostics["sourceMaxColumnTimestamp"] = self.freshness_values["source_max_column_timestamp"]
        cloud_diagnostics["sourceMaxColumnTimestampUtc"] = self.freshness_values["source_max_column_timestamp_utc"]
        cloud_diagnostics["targetMaxColumnTimestamp"] = self.freshness_values["target_max_column_timestamp"]
        cloud_diagnostics["targetMaxColumnTimestampUtc"] = self.freshness_values["target_max_column_timestamp_utc"]
        cloud_diagnostics["nowVariableName"] = self.freshness_values["now_variable_name"]
        cloud_diagnostics["nowTimestamp"] = self.freshness_values["now_timestamp"]
        cloud_diagnostics["nowTimestampUtc"] = self.freshness_values["now_timestamp_utc"]
        cloud_diagnostics["freshnessDiff"] = self.freshness_values["freshness_diff"]

        return cloud_diagnostics

    def get_cloud_dict(self):
        d = super().get_cloud_dict()

        if "dataSource" in d:
            del d["dataSource"]

        if "table" in d:
            del d["table"]

        d["dataSources"] = [
            {
                "dataSource": self.check_cfg.reconciliation_configurations["source"]["datasource"],
                "table": self.check_cfg.reconciliation_configurations["source"]["dataset"],
                "qualifier": "source",
            },
            {
                "dataSource": self.check_cfg.reconciliation_configurations["target"]["datasource"],
                "table": self.check_cfg.reconciliation_configurations["target"]["dataset"],
                "qualifier": "target",
            },
        ]

        d["group"] = {
            "identity": self.check_cfg.reconciliation_configurations["group_identity"],
            "name": self.check_cfg.reconciliation_configurations["label"],
            "distinctLabel": self.name,
            "type": "reconciliation",
        }

        return d

    def identity_datasource_part(self) -> list[str]:
        return [
            self.check_cfg.reconciliation_configurations["source"]["datasource"],
            self.check_cfg.reconciliation_configurations["source"]["dataset"],
            self.check_cfg.reconciliation_configurations["target"]["datasource"],
            self.check_cfg.reconciliation_configurations["target"]["dataset"],
        ]
