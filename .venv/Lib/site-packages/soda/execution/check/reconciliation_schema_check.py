from __future__ import annotations

from soda.execution.check.check import Check
from soda.execution.check.schema_check import SchemaCheckValidationResult
from soda.execution.check_outcome import CheckOutcome
from soda.execution.metric.metric import Metric
from soda.execution.partition import Partition
from soda.execution.reconciliation_schema_comparator import (
    ReconciliationSchemaComparator,
)
from soda.sodacl.schema_check_cfg import SchemaCheckCfg, SchemaValidations


class ReconciliationSchemaCheck(Check):
    def __init__(
        self,
        check_cfg: CheckCfg,
        data_source_scan: DataSourceScan,
        partition: Partition,
    ):
        super().__init__(
            check_cfg=check_cfg,
            data_source_scan=data_source_scan,
            partition=partition,
            column=None,
        )

        from soda.execution.table import Table

        self.measured_schema: list[dict[str, str]] | None = None
        self.schema_comparator = None

        self.warn_result: SchemaCheckValidationResult | None = None
        self.fail_result: SchemaCheckValidationResult | None = None

        from soda.execution.metric.schema_metric import SchemaMetric

        source_config = check_cfg.reconciliation_configurations["source"]
        target_config = check_cfg.reconciliation_configurations["target"]

        scan = data_source_scan.scan

        source_data_source_scan = scan._get_or_create_data_source_scan(source_config["datasource"])
        source_table: Table = source_data_source_scan.get_or_create_table(source_config["dataset"])
        # TODO get partition name from config
        source_partition = source_table.get_or_create_partition(None)

        target_data_source_scan = scan._get_or_create_data_source_scan(target_config["datasource"])
        target_table: Table = target_data_source_scan.get_or_create_table(
            target_config["dataset"]
        )  # TODO get partition name from config
        target_partition = target_table.get_or_create_partition(None)

        self.metric_values: dict = {}

        source_metric = data_source_scan.resolve_metric(
            SchemaMetric(
                data_source_scan=source_data_source_scan,
                partition=source_partition,
                check=self,
            )
        )
        target_metric = data_source_scan.resolve_metric(
            SchemaMetric(
                data_source_scan=target_data_source_scan,
                partition=target_partition,
                check=self,
            )
        )

        self.metrics["source_metric"] = source_metric
        self.metrics["target_metric"] = target_metric

    def evaluate(self, metrics: dict[str, Metric], historic_values: dict[str, object]):
        schema_check_cfg: SchemaCheckCfg = self.check_cfg

        self.source_measured_schema: list[dict[str, str]] = metrics.get("source_metric").value
        self.target_measured_schema: list[dict[str, str]] = metrics.get("target_metric").value

        source_data_source = self.metrics["source_metric"].data_source_scan.data_source
        target_data_source = self.metrics["target_metric"].data_source_scan.data_source

        self.schema_comparator = ReconciliationSchemaComparator(
            self.source_measured_schema,
            self.target_measured_schema,
            source_data_source,
            target_data_source,
            self.check_cfg.type_mappings,
        )

        self.warn_result = self.get_schema_violations(schema_check_cfg.warn_validations)
        self.fail_result = self.get_schema_violations(schema_check_cfg.fail_validations)

        if self.fail_result:
            self.outcome = CheckOutcome.FAIL
        elif self.warn_result:
            self.outcome = CheckOutcome.WARN
        else:
            self.outcome = CheckOutcome.PASS

    def get_schema_violations(
        self,
        schema_validations: SchemaValidations,
    ) -> SchemaCheckValidationResult | None:
        if schema_validations is None:
            return None

        validation_results = [
            self.schema_comparator.schema_column_deletions,
            self.schema_comparator.schema_column_type_changes,
            self.schema_comparator.schema_column_index_changes,
            self.schema_comparator.schema_column_additions,
        ]

        if any(validation_results):
            return SchemaCheckValidationResult(
                missing_column_names=self.schema_comparator.schema_column_deletions,
                column_type_changes=self.schema_comparator.schema_column_type_changes,
                column_index_changes=self.schema_comparator.schema_column_index_changes,
                column_additions=self.schema_comparator.schema_column_additions,
            )

        return None

    def get_cloud_dict(self):
        d = super().get_cloud_dict()

        if "dataSource" in d:
            del d["dataSource"]

        if "table" in d:
            del d["table"]

        d["dataSources"] = [
            {
                "dataSource": self.check_cfg.reconciliation_configurations["source"]["datasource"],
                "table": self.check_cfg.reconciliation_configurations["source"]["dataset"],
                "qualifier": "source",
            },
            {
                "dataSource": self.check_cfg.reconciliation_configurations["target"]["datasource"],
                "table": self.check_cfg.reconciliation_configurations["target"]["dataset"],
                "qualifier": "target",
            },
        ]

        d["group"] = {
            "identity": self.check_cfg.reconciliation_configurations["group_identity"],
            "name": self.check_cfg.reconciliation_configurations["label"],
            "distinctLabel": self.name,
            "type": "reconciliation",
        }

        return d

    def get_cloud_diagnostics_dict(self) -> dict:
        schema_diagnostics = {
            "blocks": [],
        }

        if self.source_measured_schema:
            columns_str = "\n".join([f'{c["name"]},{c["type"]}' for c in self.source_measured_schema])
            schema_diagnostics["blocks"].append(
                {
                    "type": "csv",
                    "text": f"Column,Type\n{columns_str}",
                    "title": "Source Schema",
                }
            )
        if self.target_measured_schema:
            columns_str = "\n".join([f'{c["name"]},{c["type"]}' for c in self.target_measured_schema])
            schema_diagnostics["blocks"].append(
                {
                    "type": "csv",
                    "text": f"Column,Type\n{columns_str}",
                    "title": "Target Schema",
                }
            )

        fail_change_events: list(dict(str, str)) = (
            self.__build_change_events(self.fail_result) if self.fail_result else []
        )
        warn_change_events: list(dict(str, str)) = (
            self.__build_change_events(self.warn_result) if self.warn_result else []
        )

        event_count = len(fail_change_events) + len(warn_change_events)

        if event_count > 0:
            fail_change_events_text = self.__build_change_events_text(fail_change_events, CheckOutcome.FAIL.name)
            warn_change_events_text = self.__build_change_events_text(warn_change_events, CheckOutcome.WARN.name)
            change_events_text = "\n".join([fail_change_events_text, warn_change_events_text])

            schema_diagnostics["blocks"].append(
                {
                    "type": "csv",
                    "text": f"Column,Event,Details\n{change_events_text}",
                    "title": "Diagnostics",
                }
            )

        schema_diagnostics["preferredChart"] = "bars"
        schema_diagnostics["valueLabel"] = f"{event_count} schema event(s)"
        schema_diagnostics["valueSeries"] = {
            "values": [
                {
                    "label": CheckOutcome.FAIL,
                    "value": len(fail_change_events),
                    "outcome": CheckOutcome.FAIL,
                },
                {
                    "label": CheckOutcome.PASS,
                    "value": len(self.source_measured_schema) + len(self.target_measured_schema) - event_count,
                    "outcome": CheckOutcome.PASS,
                },
            ]
        }

        return schema_diagnostics

    def __build_change_events(self, schema_validation_result: SchemaCheckValidationResult) -> list(dict(str, str)):
        change_events: list(dict(str, str)) = []

        for column in schema_validation_result.column_deletions:
            change_events.append(
                {
                    "column": column,
                    "event": "Exclusive in source",
                    "details": "",
                }
            )
        for column in schema_validation_result.column_additions:
            change_events.append(
                {
                    "column": column,
                    "event": "Exclusive in target",
                    "details": "",
                }
            )
        for column, index_change in schema_validation_result.column_index_changes.items():
            change_events.append(
                {
                    "column": column,
                    "event": "Index Changed",
                    "details": f"Previous Index: {index_change['previous_index']}; New Index: {index_change['new_index']}",
                }
            )
        for column, type_change in schema_validation_result.column_type_changes.items():
            change_events.append(
                {
                    "column": column,
                    "event": "Type Changed",
                    "details": f"Previous Type: {type_change['previous_type']}; New Type: {type_change['new_type']}",
                }
            )

        # Create diagnostics blocks without previous schema comparison as well.
        # Simply take outcome type and count of all changes.
        for column, type_mismatch in schema_validation_result.column_type_mismatches.items():
            change_events.append(
                {
                    "column": column,
                    "event": "Type Mismatch",
                    "details": f"Expected Type: {type_mismatch['expected_type']}; Actual Type: {type_mismatch['actual_type']}",
                }
            )
        for column in schema_validation_result.missing_column_names:
            change_events.append(
                {
                    "column": column,
                    "event": "Exclusive in source",
                    "details": "",
                }
            )
        return change_events

    def __build_change_events_text(self, change_events: list, event_type: str) -> str:
        return "\n".join(
            f"{ch['column']},:icon-{event_type.lower()}: {ch['event']}, {ch['details']}" for ch in change_events
        )

    def get_log_diagnostic_lines(self) -> list[str]:
        diagnostics_texts: list[str] = []

        if self.outcome in [CheckOutcome.FAIL, CheckOutcome.WARN]:
            if self.fail_result:
                diagnostics_texts.extend(
                    self.__build_log_diagnostic_lines(self.fail_result, CheckOutcome.FAIL.name.lower())
                )
            if self.warn_result:
                diagnostics_texts.extend(
                    self.__build_log_diagnostic_lines(self.warn_result, CheckOutcome.WARN.name.lower())
                )

        diagnostics_texts.append(f"schema_measured = {self.__schema_diagnostics_texts()}")

        return diagnostics_texts

    def __build_log_diagnostic_lines(
        self, schema_validation_result: SchemaCheckValidationResult, type: str
    ) -> list[str]:
        diagnostics_texts: list[str] = []

        if schema_validation_result.missing_column_names:
            diagnostics_texts.append(
                f"{type}_missing_column_names = {self.__list_of_texts(schema_validation_result.missing_column_names)}"
            )
        if schema_validation_result.present_column_names:
            diagnostics_texts.append(
                f"{type}_forbidden_present_column_names = {self.__list_of_texts(schema_validation_result.present_column_names)}"
            )
        if schema_validation_result.column_type_mismatches:
            for (
                column_name,
                column_type_mismatch_data,
            ) in schema_validation_result.column_type_mismatches.items():
                expected_type = column_type_mismatch_data["expected_type"]
                actual_type = column_type_mismatch_data["actual_type"]
                diagnostics_texts.append(
                    f"{type}_column_type_mismatch[{column_name}] expected({expected_type}) actual({actual_type})"
                )
        if schema_validation_result.column_index_mismatches:
            for (
                column_name,
                column_index_mismatch_data,
            ) in schema_validation_result.column_index_mismatches.items():
                expected_index = column_index_mismatch_data["expected_index"]
                actual_index = column_index_mismatch_data["actual_index"]
                column_on_expected_index = column_index_mismatch_data["column_on_expected_index"]
                column_on_expected_index_text = (
                    f"{type}_column_on_expected_index({column_on_expected_index})" if column_on_expected_index else ""
                )
                diagnostics_texts.append(
                    f"{type}_column_index_mismatch[{column_name}] expected({expected_index}) actual({actual_index}){column_on_expected_index_text}"
                )

        if self.schema_comparator:
            if schema_validation_result.column_additions:
                diagnostics_texts.append(
                    f"{type}_column_additions = {self.__list_of_texts(schema_validation_result.column_additions)}"
                )
            if schema_validation_result.column_deletions:
                diagnostics_texts.append(
                    f"{type}_column_deletions = {self.__list_of_texts(schema_validation_result.column_deletions)}"
                )
            if schema_validation_result.column_type_changes:
                for (
                    column_name,
                    column_type_change_data,
                ) in schema_validation_result.column_type_changes.items():
                    previous_type = column_type_change_data["previous_type"]
                    new_type = column_type_change_data["new_type"]
                    diagnostics_texts.append(
                        f"{type}_column_type_change[{column_name}] new_type({new_type}) previous_type({previous_type})"
                    )
            if schema_validation_result.column_index_changes:
                changes = []
                for (
                    column_name,
                    column_index_change_data,
                ) in schema_validation_result.column_index_changes.items():
                    previous_index = column_index_change_data["previous_index"]
                    new_index = column_index_change_data["new_index"]
                    changes.append(f"{column_name}[{previous_index}->{new_index}]")
                changes_txt = ", ".join(changes)
                diagnostics_texts.append(f"{type}_column_index_changes = {changes_txt}")

        return diagnostics_texts

    def __list_of_texts(self, texts):
        elements = ", ".join(texts)
        return f"[{elements}]"

    def __schema_diagnostics_texts(self) -> str:
        if not self.measured_schema:
            return "[]"

        return self.__list_of_texts((column["name"] + " " + column["type"]) for column in self.measured_schema)

    def identity_datasource_part(self) -> list[str]:
        return [
            self.check_cfg.reconciliation_configurations["source"]["datasource"],
            self.check_cfg.reconciliation_configurations["source"]["dataset"],
            self.check_cfg.reconciliation_configurations["target"]["datasource"],
            self.check_cfg.reconciliation_configurations["target"]["dataset"],
        ]
