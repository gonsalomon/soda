from __future__ import annotations

from deepdiff import DeepDiff
from deepdiff.helper import CannotCompare

from soda.execution.check.check import Check
from soda.execution.check_outcome import CheckOutcome
from soda.execution.metric.metric import Metric
from soda.execution.metric.reconciliation_row_diff_metric import (
    ReconciliationRowDiffMetric,
)
from soda.execution.table import Table
from soda.sampler.in_memory_sample import InMemorySample
from soda.sampler.sample_context import SampleContext
from soda.sampler.sampler import Sampler
from soda.sodacl.reconciliation_row_diff_check_cfg import ReconciliationRowDiffCheckCfg


class ReconciliationRowDiffCheck(Check):
    def __init__(
        self, check_cfg: ReconciliationRowDiffCheckCfg, data_source_scan: DataSourceScan, partition: Partition
    ):
        super().__init__(check_cfg=check_cfg, data_source_scan=data_source_scan, partition=partition, column=None)
        self.check_cfg = check_cfg
        self.data_source_scan = data_source_scan
        self.partition = partition

        scan = data_source_scan.scan

        source_config = check_cfg.reconciliation_configurations["source"]
        target_config = check_cfg.reconciliation_configurations["target"]
        self.source_key_columns = check_cfg.source_key_columns
        self.target_key_columns = check_cfg.target_key_columns

        source_data_source_scan = scan._get_or_create_data_source_scan(source_config["datasource"])
        source_table: Table = source_data_source_scan.get_or_create_table(source_config["dataset"])
        source_partition = source_table.get_or_create_partition(None)
        source_filter = source_config.get("filter")

        target_data_source_scan = scan._get_or_create_data_source_scan(target_config["datasource"])
        target_table: Table = target_data_source_scan.get_or_create_table(target_config["dataset"])
        target_partition = target_table.get_or_create_partition(None)
        target_filter = target_config.get("filter")

        self.diff_config = check_cfg.diff_config

        self.metrics = {}

        src_columns = "*"
        if check_cfg.source_columns:
            src_columns = check_cfg.source_columns

            for src_key_column in check_cfg.source_key_columns:
                if src_key_column not in src_columns:
                    src_columns.append(src_key_column)

        tgt_columns = "*"
        if check_cfg.target_columns:
            tgt_columns = check_cfg.target_columns

            for tgt_key_column in check_cfg.target_key_columns:
                if tgt_key_column not in tgt_columns:
                    tgt_columns.append(tgt_key_column)

        source_metric = ReconciliationRowDiffMetric(
            data_source_scan=source_data_source_scan,
            check=self,
            partition=source_partition,
            filter=source_filter,
            columns=src_columns,
        )
        target_metric = ReconciliationRowDiffMetric(
            data_source_scan=target_data_source_scan,
            check=self,
            partition=target_partition,
            filter=target_filter,
            columns=tgt_columns,
        )

        self.metrics["source_metric"] = source_data_source_scan.resolve_metric(source_metric)
        self.metrics["target_metric"] = target_data_source_scan.resolve_metric(target_metric)

        self.outcome_dict = {}

    def evaluate(self, metrics: dict[str, Metric], historic_values: dict[str, object]):
        source_columns = self.metrics["source_metric"].result_columns
        source_metric_values = metrics.get("source_metric").value

        target_columns = self.metrics["target_metric"].result_columns
        target_metric_values = metrics.get("target_metric").value

        # Do not compute if source/target columns are not specified and # of src/tgt columns are different as that leads to errors.
        if len(self.metrics["source_metric"].result_columns) != len(self.metrics["target_metric"].result_columns):
            self.check_value = None
            self.logs.error(
                f"Cannot evaluate '{self.check_cfg.name}' check. Target and source schemas are not similar. Source and target columns are not specified."
            )
            return

        def compare_func(x, y, level=None):
            try:
                # Y is source X is target. Duh. Only an hour of debugging to figure that out.
                source_columns = self.metrics["source_metric"].result_columns
                target_columns = self.metrics["target_metric"].result_columns
                for src_kc, tgt_kc in zip(self.source_key_columns, self.target_key_columns):
                    src_kc_index = source_columns.index(src_kc)
                    tgt_kc_index = target_columns.index(tgt_kc)
                    if y[src_kc_index] != x[tgt_kc_index]:
                        return False
                return True
            except KeyError:
                raise CannotCompare() from None

        iterable_compare_func = None
        if self.source_key_columns and self.target_key_columns:
            iterable_compare_func = compare_func

        diff_config = {
            "ignore_order": True,
            "report_repetition": True,
            "iterable_compare_func": iterable_compare_func,
            "cutoff_intersection_for_pairs": 0.7,
        }
        if self.diff_config:
            diff_config.update(self.diff_config)

        from soda.scan import verbose

        if verbose:
            from pprint import pprint

            self.logs.debug(f"Starting diff with config:")
            pprint(diff_config)

        diff = DeepDiff(source_metric_values, target_metric_values, **diff_config)

        if verbose:
            pprint(diff)

        changed = 0
        added = 0
        removed = 0

        if diff:
            allow_samples = True
            src_offending_columns = []
            tgt_offending_columns = []

            src_tgt_cols = []
            for i in range(0, len(self.source_key_columns)):
                if self.source_key_columns[i] == self.target_key_columns[i]:
                    column_header = self.source_key_columns[i]
                else:
                    column_header = f"{self.source_key_columns[i]} -> {self.target_key_columns[i]}"
                src_tgt_cols.append(column_header)
            samples_schema = src_tgt_cols + ["event", "column", "source", "target"]
            samples = []

            is_column_excluded = self.data_source_scan.data_source.is_column_excluded
            src_table = self.metrics["source_metric"].partition.table.table_name
            tgt_table = self.metrics["target_metric"].partition.table.table_name

            src_columns = self.metrics["source_metric"].result_columns
            tgt_columns = self.metrics["target_metric"].result_columns

            for src_column in self.metrics["source_metric"].columns:
                if is_column_excluded(src_table, src_column):
                    src_offending_columns.append(src_column)
                    allow_samples = False

            for tgt_column in self.metrics["target_metric"].columns:
                if is_column_excluded(tgt_table, tgt_column):
                    tgt_offending_columns.append(tgt_column)
                    allow_samples = False

            if "values_changed" in diff:
                changed = len(diff["values_changed"])
                for key, row_diff in diff["values_changed"].items():
                    samples.append(
                        self._diff_changed_to_sample(
                            self._diff_parse_key(key),
                            row_diff,
                            source_metric_values,
                            target_metric_values,
                            source_columns,
                            target_columns,
                        )
                    )

            if "iterable_item_added" in diff:
                added = len(diff["iterable_item_added"])

                for key, row_diff in diff["iterable_item_added"].items():
                    row_diff = {src_columns[k]: v for k, v in row_diff.items()}
                    samples.append(
                        self._diff_added_to_sample(
                            self._diff_parse_key(key), row_diff, source_metric_values, target_metric_values
                        )
                    )

            if "iterable_item_removed" in diff:
                removed = len(diff["iterable_item_removed"])

                for key, row_diff in diff["iterable_item_removed"].items():
                    row_diff = {tgt_columns[k]: v for k, v in row_diff.items()}
                    samples.append(
                        self._diff_removed_to_sample(
                            self._diff_parse_key(key), row_diff, source_metric_values, target_metric_values
                        )
                    )

            if allow_samples and samples:
                sampler: Sampler = self.data_source_scan.scan._configuration.sampler
                sample_context = SampleContext(
                    sample=InMemorySample(samples, samples_schema, data_source=self.data_source_scan.data_source),
                    sample_name="failed rows",
                    query="",
                    data_source=self.data_source_scan.data_source,
                    partition=self.partition,
                    column=None,
                    scan=self.data_source_scan.scan,
                    logs=self.data_source_scan.scan._logs,
                    samples_limit=self.check_cfg.samples_limit,
                    passing_sql="",
                    check_name=self.name,
                )

                self.failed_rows_sample_ref = sampler.store_sample(sample_context)

        self.check_value = changed + added + removed
        self.set_outcome_based_on_check_value()

        self.outcome_dict = {
            "changed": changed,
            "added": added,
            "removed": removed,
            "source_count": len(source_metric_values),
            "target_count": len(target_metric_values),
        }

    def _diff_parse_key(self, key: str) -> dict[str, any]:
        import re

        parsed = {"index": None, "column": None}
        key_parts = re.findall(r"\['?(.*?)'?\]", key)

        if key_parts:
            # The first part is always the index
            parsed["index"] = int(key_parts[0])

            if len(key_parts) > 1:
                # Second part is the column index
                parsed["column"] = int(key_parts[1])
        return parsed

    def _diff_changed_to_sample(
        self,
        key_parts: list[str],
        row_diff: dict,
        src_data: dict,
        tgt_data: dict,
        source_columns: list[str],
        target_columns: list[str],
    ) -> list[str]:
        value = []

        if key_parts["index"] is not None:
            # The key columns.
            for key_column in self.source_key_columns:
                key_column_index = self.metrics["source_metric"].result_columns.index(key_column)
                value.append(src_data[key_parts["index"]][key_column_index])

            # Event type.
            value.append("Changed")

            # The column name(s) affected.
            src_col = source_columns[key_parts["column"]]
            tgt_col = target_columns[key_parts["column"]]
            if src_col == tgt_col:
                value.append(src_col)
            else:
                value.append(f"{src_col} -> {tgt_col}")

            value.extend(
                [
                    self._dict_to_str_remove_top_brackets(row_diff["old_value"]),
                    self._dict_to_str_remove_top_brackets(row_diff["new_value"]),
                ]
            )

        return value

    def _diff_added_to_sample(self, key_parts: list[str], row_diff: dict, src_data: dict, tgt_data: dict) -> list[str]:
        value = []

        if key_parts["index"] is not None:
            for key_column in self.source_key_columns:
                key_column_index = self.metrics["source_metric"].result_columns.index(key_column)
                value.append(tgt_data[key_parts["index"]][key_column_index])

            value.extend(["Exclusive in target", "", "", ""])

        return value

    def _diff_removed_to_sample(
        self, key_parts: list[str], row_diff: dict, src_data: dict, tgt_data: dict
    ) -> list[str]:
        value = []

        if key_parts["index"] is not None:
            for key_column in self.source_key_columns:
                key_column_index = self.metrics["source_metric"].result_columns.index(key_column)
                value.append(src_data[key_parts["index"]][key_column_index])

            value.extend(["Exclusive in source", "", "", ""])

        return value

    def _dict_to_str_remove_top_brackets(self, d: dict) -> str:
        s = str(d)

        if s.startswith("{"):
            s = s[1:]
        if s.endswith("}"):
            s = s[:-1]

        return s

    def get_log_diagnostic_dict(self) -> dict:
        d = super().get_log_diagnostic_dict()

        d["source_count"] = self.outcome_dict.get("source_count")
        d["target_count"] = self.outcome_dict.get("target_count")
        d["changed"] = self.outcome_dict.get("changed")
        d["added"] = self.outcome_dict.get("added")
        d["removed"] = self.outcome_dict.get("removed")

        return d

    def get_cloud_diagnostics_dict(self) -> dict:
        cloud_diagnostics = super().get_cloud_diagnostics_dict()

        diagnostic_text = ""
        for key, value in self.outcome_dict.items():
            diagnostic_text += f"{key.replace('_', ' ').title()}, {value}\n"

        diagnostics_block = {
            "type": "csv",
            "title": "Diagnostics",
            "text": f"Event, Value\n{diagnostic_text}",
        }
        cloud_diagnostics["blocks"].append(diagnostics_block)

        return cloud_diagnostics

    def set_outcome_based_on_check_value(self):
        reconciliation_check_cfg = self.check_cfg
        if self.check_value is not None and reconciliation_check_cfg.has_threshold():
            reconciliation_check_cfg.resolve_thresholds(self.data_source_scan.scan.jinja_resolve)
            if reconciliation_check_cfg.fail_threshold_cfg and reconciliation_check_cfg.fail_threshold_cfg.is_bad(
                self.check_value
            ):
                self.outcome = CheckOutcome.FAIL
            elif reconciliation_check_cfg.warn_threshold_cfg and reconciliation_check_cfg.warn_threshold_cfg.is_bad(
                self.check_value
            ):
                self.outcome = CheckOutcome.WARN
            else:
                self.outcome = CheckOutcome.PASS

    def get_cloud_dict(self):
        d = super().get_cloud_dict()

        if "dataSource" in d:
            del d["dataSource"]

        if "table" in d:
            del d["table"]

        d["dataSources"] = [
            {
                "dataSource": self.check_cfg.reconciliation_configurations["source"]["datasource"],
                "table": self.check_cfg.reconciliation_configurations["source"]["dataset"],
                "qualifier": "source",
            },
            {
                "dataSource": self.check_cfg.reconciliation_configurations["target"]["datasource"],
                "table": self.check_cfg.reconciliation_configurations["target"]["dataset"],
                "qualifier": "target",
            },
        ]

        d["group"] = {
            "identity": self.check_cfg.reconciliation_configurations["group_identity"],
            "name": self.check_cfg.reconciliation_configurations["label"],
            "distinctLabel": self.name,
            "type": "reconciliation",
        }

        return d

    def identity_datasource_part(self) -> list[str]:
        return [
            self.check_cfg.reconciliation_configurations["source"]["datasource"],
            self.check_cfg.reconciliation_configurations["source"]["dataset"],
            self.check_cfg.reconciliation_configurations["target"]["datasource"],
            self.check_cfg.reconciliation_configurations["target"]["dataset"],
        ]
